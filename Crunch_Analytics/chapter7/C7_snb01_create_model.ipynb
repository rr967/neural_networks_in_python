{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a churn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the most recent data\n",
    "app_df = pd.read_csv('data/data_jun.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ASSUMPTION **\n",
    "\n",
    "We are going to view each of these observations as 'individual' observations, which is an oversimplification of the true nature of a churn problem since these observations are of course not independent - and in an ideal scenario a churn model includes quite a lot more complex analysis (offsets,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_df.drop(['month'], axis=1, inplace=True)\n",
    "app_df.drop(['userId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "app_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(app_df, hue = 'churn', vars = ['app_usage', 'sub_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something weird is going on with the subscription amount, but the explanation is quite obvious..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put sub_amount on same scale\n",
    "def sub_amount_transformer(x):\n",
    "    if x['payment_freq'] == 'Quarterly':\n",
    "        return x['sub_amount'] * 4\n",
    "    elif x['payment_freq'] == 'Monthly':\n",
    "        return x['sub_amount'] * 12\n",
    "    else:\n",
    "        return x['sub_amount']\n",
    "        \n",
    "app_df['sub_amount'] = app_df.apply(lambda x: sub_amount_transformer(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(app_df, hue = 'churn', vars = ['app_usage', 'sub_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add dummy variables for categorical variables\n",
    "app_df = pd.get_dummies(data = app_df, columns = ['payment_method', 'payment_freq', 'platform'])\n",
    "\n",
    "#dummies for location\n",
    "app_df['location_be'] = [1 if x == 0 else 0 for x in app_df['location']]\n",
    "app_df.rename(columns={'location': 'location_nl'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make y, X variables\n",
    "y = app_df['churn']\n",
    "X = app_df.drop([\"churn\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into test and training (30% for test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the classifier using the train data\n",
    "rf = rf.fit(X_train, Y_train)\n",
    "\n",
    "# Validate the classifier\n",
    "accuracy = rf.score(X_test, Y_test)\n",
    "print('Accuracy on test set: ' + str(accuracy))\n",
    "\n",
    "# Make a confusion matrix\n",
    "prediction = rf.predict(X_test)\n",
    "\n",
    "conf_matrix = pd.DataFrame(\n",
    "    confusion_matrix(Y_test, prediction), \n",
    "    columns=[\"Predicted False\", \"Predicted True\"], \n",
    "    index=[\"Actual False\", \"Actual True\"]\n",
    ")\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look with some greater detail at what is being predicted \n",
    "sns.distplot(rf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate probabilities that customer will churn for test set\n",
    "probs = rf.predict_proba(X_test)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(Y_test, probs[:,1])\n",
    "\n",
    "#calculate area under curve\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('True Positive Rate (sensitivity / recall)')\n",
    "plt.xlabel('False Positive Rate (1- specificity)')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a \"pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild model for every month when we get a new data dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(csv_name):\n",
    "    \n",
    "    #import data\n",
    "    import pandas as pd\n",
    "    path = str('data/' + csv_name + '.csv')\n",
    "    app_df = pd.read_csv(path, index_col = 0)\n",
    "    \n",
    "    #only keep new data from current month\n",
    "    app_df = app_df.loc[app_df['month'] == csv_name.split('_')[1]]\n",
    "    \n",
    "    print('training on month: ' + app_df.month.unique())\n",
    "    print('number of rows: ' + str(len(app_df)))\n",
    "    #print 'value counts ' + str(app_df.churn.value_counts())\n",
    "    \n",
    "    app_df = app_df.drop(['month'], axis = 1) \n",
    "    \n",
    "    #drop userid cause it's not important\n",
    "    userId = app_df['userId']\n",
    "    app_df = app_df.drop(['userId'], axis = 1)\n",
    "    \n",
    "    #put sub_amount on same scale\n",
    "    def sub_amount_transformer(x):\n",
    "        if x['payment_freq'] == 'Quarterly':\n",
    "            return x['sub_amount'] * 4\n",
    "        elif x['payment_freq'] == 'Monthly':\n",
    "            return x['sub_amount'] * 12\n",
    "        else:\n",
    "            return x['sub_amount']\n",
    "\n",
    "    app_df['sub_amount'] = app_df.apply(lambda x: sub_amount_transformer(x), axis = 1)\n",
    "    \n",
    "    #add dummy variables for categorical variables\n",
    "    app_df = pd.get_dummies(data = app_df, columns = ['payment_method', 'payment_freq', 'platform'])\n",
    "\n",
    "    #dummies for location\n",
    "    app_df['location_be'] = [1 if x == 0 else 0 for x in app_df['location']]\n",
    "    app_df.rename(columns={'location': 'location_nl'}, inplace=True)\n",
    "    \n",
    "    #make y, X variables\n",
    "    y = app_df['churn']\n",
    "    X = app_df.drop([\"churn\"], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_churn_model(csv_name):\n",
    "    \n",
    "    X, y = load_and_preprocess_data(csv_name)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Split the data into test and training (30% for test)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify = y,\n",
    "                                                        random_state = 123)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Train the classifier using the train data\n",
    "    rf = rf.fit(X_train, Y_train)\n",
    "\n",
    "    # Validate the classifier\n",
    "    accuracy = rf.score(X_test, Y_test)\n",
    "    print('Accuracy on test set: ' + str(accuracy))\n",
    "\n",
    "    # Make a confusion matrix\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "    conf_matrix = pd.DataFrame(\n",
    "        confusion_matrix(Y_test, prediction), \n",
    "        columns=[\"Predicted False\", \"Predicted True\"], \n",
    "        index=[\"Actual False\", \"Actual True\"]\n",
    "    )\n",
    "\n",
    "    conf_matrix\n",
    "    \n",
    "    return rf, accuracy, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf, acc, conf_matrix = make_churn_model('data_may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-use old model for new data dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(csv_name, rf):\n",
    "    \n",
    "    X, y = load_and_preprocess_data(csv_name)\n",
    "    \n",
    "    # Validate the classifier\n",
    "    accuracy = rf.score(X, y)\n",
    "    print('Accuracy on test set: ' + str(accuracy))\n",
    "\n",
    "    # Make a confusion matrix\n",
    "    prediction = rf.predict(X)\n",
    "\n",
    "    conf_matrix = pd.DataFrame(\n",
    "        confusion_matrix(y, prediction), \n",
    "        columns=[\"Predicted False\", \"Predicted True\"], \n",
    "        index=[\"Actual False\", \"Actual True\"]\n",
    "    )\n",
    "    \n",
    "    return accuracy, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf, acc, conf_matrix = make_churn_model('data_may')\n",
    "acc, conf_matrix = test_model('data_jun', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rebuild model for every month when we get a new data dump\n",
    "\n",
    "def load_and_preprocess_data(csv_name):\n",
    "    \n",
    "    #import data\n",
    "    import pandas as pd\n",
    "    path = str('data/' + csv_name + '.csv')\n",
    "    app_df = pd.read_csv(path, index_col = 0)\n",
    "    \n",
    "    #only keep new data from current month\n",
    "    app_df = app_df.loc[app_df['month'] == csv_name.split('_')[1]]\n",
    "    \n",
    "    print('training on month: ' + app_df.month.unique())\n",
    "    print('number of rows: ' + str(len(app_df)))\n",
    "    #print 'value counts ' + str(app_df.churn.value_counts())\n",
    "    \n",
    "    app_df = app_df.drop(['month'], axis = 1) \n",
    "    \n",
    "    #drop userid cause it's not important\n",
    "    userId = app_df['userId']\n",
    "    app_df = app_df.drop(['userId'], axis = 1)\n",
    "    \n",
    "    #put sub_amount on same scale\n",
    "    def sub_amount_transformer(x):\n",
    "        if x['payment_freq'] == 'Quarterly':\n",
    "            return x['sub_amount'] * 4\n",
    "        elif x['payment_freq'] == 'Monthly':\n",
    "            return x['sub_amount'] * 12\n",
    "        else:\n",
    "            return x['sub_amount']\n",
    "\n",
    "    app_df['sub_amount'] = app_df.apply(lambda x: sub_amount_transformer(x), axis = 1)\n",
    "    \n",
    "    #add dummy variables for categorical variables\n",
    "    app_df = pd.get_dummies(data = app_df, columns = ['payment_method', 'payment_freq', 'platform'])\n",
    "\n",
    "    #dummies for location\n",
    "    app_df['location_be'] = [1 if x == 0 else 0 for x in app_df['location']]\n",
    "    app_df.rename(columns={'location': 'location_nl'}, inplace=True)\n",
    "    \n",
    "    #make y, X variables\n",
    "    y = app_df['churn']\n",
    "    X = app_df.drop([\"churn\"], axis=1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def make_churn_model(csv_name):\n",
    "    \n",
    "    X, y = load_and_preprocess_data(csv_name)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Split the data into test and training (30% for test)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size=0.25,\n",
    "                                                        stratify = y,\n",
    "                                                        random_state = 123)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Train the classifier using the train data\n",
    "    rf = rf.fit(X_train, Y_train)\n",
    "\n",
    "    # Validate the classifier\n",
    "    accuracy = rf.score(X_test, Y_test)\n",
    "    print('Accuracy on test set: ' + str(accuracy))\n",
    "\n",
    "    # Make a confusion matrix\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "    conf_matrix = pd.DataFrame(\n",
    "        confusion_matrix(Y_test, prediction), \n",
    "        columns=[\"Predicted False\", \"Predicted True\"], \n",
    "        index=[\"Actual False\", \"Actual True\"]\n",
    "    )\n",
    "\n",
    "    conf_matrix\n",
    "    \n",
    "    return rf, accuracy, conf_matrix\n",
    "\n",
    "rf, acc, conf_matrix = make_churn_model('data_may')\n",
    "\n",
    "conf_matrix\n",
    "\n",
    "# Re-use old model for new data dumps\n",
    "\n",
    "def test_model(csv_name, rf):\n",
    "    \n",
    "    X, y = load_and_preprocess_data(csv_name)\n",
    "    \n",
    "    # Validate the classifier\n",
    "    accuracy = rf.score(X, y)\n",
    "    print('Accuracy on test set: ' + str(accuracy))\n",
    "\n",
    "    # Make a confusion matrix\n",
    "    prediction = rf.predict(X)\n",
    "\n",
    "    conf_matrix = pd.DataFrame(\n",
    "        confusion_matrix(y, prediction), \n",
    "        columns=[\"Predicted False\", \"Predicted True\"], \n",
    "        index=[\"Actual False\", \"Actual True\"]\n",
    "    )\n",
    "    \n",
    "    return accuracy, conf_matrix\n",
    "\n",
    "rf, acc, conf_matrix = make_churn_model('data_may')\n",
    "acc, conf_matrix = test_model('data_jun', rf)\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the functions defined above to a file allows you to test new data like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the 3 functions we defined from the model building notebook and new one to split data\n",
    "from model_functions_3 import load_and_preprocess_data, make_churn_model, test_model, import_data_and_split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train model on june data\n",
    "rf, acc, conf_matrix = make_churn_model('data_may')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test the model on new data from july\n",
    "acc, conf_matrix = test_model('data_jun', rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
<<<<<<< Updated upstream
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
=======
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
