{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6 Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the speed of normal logistic regression vs. logistic regression that uses stochastic gradient descent to fit it's parameters. The topic if the excercise is irrelevant (it's hard to find a good example, as you need a huge database to find a notable performance improvement). For those interested, it concerns an emailclassifier. It reads an email and models what the topic of the email is. So, this is actually your first natural language processing example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the array into memory\n",
    "X_train_np = np.load('data/sgd_X_train_np.npz')['arr_0']\n",
    "X_test_np = np.load('data/sgd_X_test_np.npz')['arr_0']\n",
    "Y_train_np = np.load('data/sgd_target_Y_train_np.npz')['arr_0']\n",
    "Y_test_np = np.load('data/sgd_target_Y_test_np.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np[0] #example of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_np \n",
    "# Each Y is actually a topic 1='alt.atheism', 2='talk.religion.misc', 3='comp.graphics', 4='sci.space'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from the training dataset using a sparse vectorizer\n",
    "use_hashing = True\n",
    "n_features = 500\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "if use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', n_features=n_features)\n",
    "    X_train = vectorizer.transform(X_train_np)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(X_train_np)\n",
    "\n",
    "duration = time() - t0\n",
    "print(\"completed in: \" + str(duration) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features from the test dataset using the same vectorizer\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(X_test_np)\n",
    "duration = time() - t0\n",
    "print(\"completed in: \" + str(duration) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from integer feature name to original token string\n",
    "if use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the part where we are interested in, comparing speed of the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, Y_train_np.astype(np.int))\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "  \n",
    "    acc = clf.score(X_test, Y_test_np.astype(np.int))\n",
    "    print('Score: ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "iterations = 2\n",
    "benchmark(SGDClassifier(loss='log', alpha=.001, max_iter=iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is very similar but the time to train is faster. For this example the training time is negligible, but think about if the training data would be 1000 - 1 million times bigger. Which in reality is often the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources for Notebook:\n",
    "- Nullege.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
