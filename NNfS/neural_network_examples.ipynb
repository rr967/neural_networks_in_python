{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# importing python module named numpy\nimport sys\nimport os\nimport numpy as np\nimport inspect\nimport matplotlib",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import nnfs\nfrom nnfs.datasets import spiral_data  # See for code: https://gist.github.com/Sentdex/454cb20ec5acf0e76ee8ab8448e6266c\n\nnnfs.init()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# ex. 1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "'''\nCreates a basic neuron with 3 inputs.\n\nAssociated YT NNFS tutorial: https://www.youtube.com/watch?v=Wo5dMEP_BbI\n'''\n\ninputs = [1.2, 5.1, 2.1]\nweights = [3.1, 2.1, 8.7]\nbias = 3.0\n\noutput = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\nprint(output)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "35.7\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "# ex. 2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "'''\nCreates a simple layer of neurons, with 4 inputs.\n\nAssociated YT NNFS tutorial: https://www.youtube.com/watch?v=lGLto9Xd7bU\n'''\n\ninputs = [1.0, 2.0, 3.0, 2.5]\n\nweights1 = [0.2, 0.8, -0.5, 1.0]\nweights2 = [0.5, -0.91, 0.26, -0.5]\nweights3 = [-0.26, -0.27, 0.17, 0.87]\n\nbias1 = 2.0\nbias2 = 3.0\nbias3 = 0.5\n\noutput = [inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]*weights1[3] + bias1,\n          inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]*weights2[3] + bias2,\n          inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]*weights3[3] + bias3]\nprint(output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[4.8, 1.21, 2.385]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "# ex. 3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "'''\nDoing dot product with a layer of neurons and multiple inputs\n\nAssociated YT NNFS tutorial: https://www.youtube.com/watch?v=tMrbN67U9d4\n'''\n\nimport numpy as np \n\ninputs = [1.0, 2.0, 3.0, 2.5]\nweights = [[0.2, 0.8, -0.5, 1.0],\n           [0.5, -0.91, 0.26, -0.5],\n           [-0.26, -0.27, 0.17, 0.87]]\n\nbiases = [2.0, 3.0, 0.5]\n\noutput = np.dot(np.array(weights), np.array(inputs)) + biases\nprint(output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[4.79999995 1.21000004 2.38499999]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "# ex. 4",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "'''\nUsing objects for adding hidden layers\n\nAssociated YT tutorial: https://youtu.be/TEWy9vZcxW4\n'''\n\nimport numpy as np\n\n# we use this function to reproduce every time the same result (done in nnfs.init)\n# np.random.seed(0)\n\nX = [[1, 2, 3, 2.5],\n     [2.0, 5.0, -1.0, 2.0],\n     [-1.5, 2.7, 3.3, -0.8]]\n\nclass Layer_Dense:\n\n    def __init__(self, n_inputs, n_neurons):\n        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n        self.biases = np.zeros((1, n_neurons))\n\n    def forward(self, inputs):\n        self.output = np.dot(np.array(inputs), self.weights) + self.biases\n\nlayer1 = Layer_Dense(4,5)\nlayer2 = Layer_Dense(5,2)\n\nlayer1.forward(X)\n# print(layer1.output)\nlayer2.forward(layer1.output)\nprint(layer2.output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[ 0.148296   -0.08397602]\n [ 0.14100316 -0.01340469]\n [ 0.20124978 -0.07290616]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "# ex. 5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "'''\nAdding activation function\n\nAssociated YT tutorial: https://www.youtube.com/watch?v=gmjzbpSVY1A&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&index=5\n'''\n\nimport numpy as np \nimport nnfs\n# from nnfs.datasets import spiral_data  # See for code: https://gist.github.com/Sentdex/454cb20ec5acf0e76ee8ab8448e6266c\n\ndef spiral_data(points, classes):\n    X = np.zeros((points*classes, 2))\n    y = np.zeros(points*classes, dtype='uint8')\n    for class_number in range(classes):\n        ix = range(points*class_number, points*(class_number+1))\n        r = np.linspace(0.0, 1, points)  # radius\n        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n        y[ix] = class_number\n    return X, y\n\nnnfs.init()\n\n# we use this function to reproduce every time the same result (done in nnfs.init)\n# np.random.seed(0)\n\nX, y = spiral_data(100, 3)   \n\nclass Layer_Dense:\n    def __init__(self, n_inputs, n_neurons):\n        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n        self.biases = np.zeros((1, n_neurons))\n    def forward(self, inputs):\n        self.output = np.dot(np.array(inputs), self.weights) + self.biases\n\n# Activation function = step unit\n\nclass Activation_Step:\n    def forward(self, inputs):\n        for i in inputs:\n            if i > 0:\n                self.output.append(1)\n            else:\n                self.output.append(0)\n\n# Activation function = sigmoid\n\nclass Activation_Sigmoid:\n    def forward(self, inputs):\n        for i in inputs:\n            if i > 0:\n                self.output.append(1 / (1 - math.exp(-1*abs(i))))\n            else:\n                self.output.append(0)\n\n# Activation function = Rectified Linear Unit ( ReLU )\n\nclass Activation_ReLU:\n    def forward(self, inputs):\n        #for i in inputs:\n        #    if i > 0:\n        #        self.output.append(i)\n        #    else:\n        #        self.output.append(0)\n        \n        self.output = np.maximum(0, inputs)\n\nlayer1 = Layer_Dense(2,5)\nactivation1 = Activation_ReLU()\n\nlayer1.forward(X)\n\n#print(layer1.output)\nactivation1.forward(layer1.output)\nprint(activation1.output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504505e-04\n  4.56846210e-05]\n [0.00000000e+00 5.93469958e-05 0.00000000e+00 2.03573116e-04\n  6.10024377e-04]\n ...\n [1.13291524e-01 0.00000000e+00 0.00000000e+00 8.11079666e-02\n  0.00000000e+00]\n [1.34588361e-01 0.00000000e+00 3.09493970e-02 5.66337556e-02\n  0.00000000e+00]\n [1.07817926e-01 0.00000000e+00 0.00000000e+00 8.72561932e-02\n  0.00000000e+00]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "'''\nAssociated YT tutorial: https://www.youtube.com/watch?v=omz_NdFgWyU&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&index=7\n'''\n\n# code to match https://www.youtube.com/watch?v=omz_NdFgWyU&list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3&index=6\nimport numpy as np \nimport nnfs\nfrom nnfs.datasets import spiral_data\n\n\nnnfs.init()\n\nclass Layer_Dense:\n    def __init__(self, n_inputs, n_neurons):\n        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n        self.biases = np.zeros((1, n_neurons))\n    def forward(self, inputs):\n        self.output = np.dot(inputs, self.weights) + self.biases\n\n\nclass Activation_ReLU:\n    def forward(self, inputs):\n        self.output = np.maximum(0, inputs)\n\nclass Activation_Softmax:\n    def forward(self, inputs):\n        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n        self.output = probabilities\n\n\nX, y = spiral_data(samples=100, classes=3)\n\ndense1 = Layer_Dense(2,3)\nactivation1 = Activation_ReLU()\n\ndense2 = Layer_Dense(3, 3)\nactivation2 = Activation_Softmax()\n\ndense1.forward(X)\nactivation1.forward(dense1.output)\n\ndense2.forward(activation1.output)\nactivation2.forward(dense2.output)\n\nprint(activation2.output[:5])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[0.33333334 0.33333334 0.33333334]\n [0.33331734 0.33331832 0.33336434]\n [0.3332888  0.33329153 0.33341965]\n [0.33325943 0.33326396 0.33347666]\n [0.33323312 0.33323926 0.33352762]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}