{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "270a1fc8-7de0-4cae-9a52-3e645924da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL: https://github.com/Sentdex/nnfs_book/blob/main/Chapter_6/Ch6_final.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00dc554-c608-47df-a0b5-802f07eda560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import vertical_data\n",
    "\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9c1149-bac2-475d-a382-5fd2620f978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076ce798-4abe-4026-9524-8e0160f26f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "984dcb79-3ca4-471e-a94a-0ac2c334b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293909e6-8b1f-45db-bc29-7bafd3928b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdb6260c-c345-4bae-b2c4-9c707cb4757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped*y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd721b32-5164-43f8-98d2-a265f63fab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = vertical_data(samples=100, classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba2a62f2-4bcc-48b0-84fb-d06aea9f385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "dense1 = Layer_Dense(2, 3)  # first dense layer, 2 inputs\n",
    "activation1 = Activation_ReLU()\n",
    "dense2 = Layer_Dense(3, 3)  # second dense layer, 3 inputs, 3 outputs\n",
    "activation2 = Activation_Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67aa224-2264-40e4-9941-cf7a4b887897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "loss_function = Loss_CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c69f80-58d9-4473-8209-481226ef8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variables\n",
    "lowest_loss = 9999999  # some initial value\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab0113a5-074e-4017-8053-05162374e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration: 0 loss: 1.0987684 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 1 loss: 1.0987465 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 5 loss: 1.0976487 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 6 loss: 1.0972018 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 10 loss: 1.0938749 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 19 loss: 1.0935849 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 20 loss: 1.0908297 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 21 loss: 1.0905013 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 22 loss: 1.0879314 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 24 loss: 1.0856307 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 25 loss: 1.0801181 acc: 0.35\n",
      "New set of weights found, iteration: 29 loss: 1.0725244 acc: 0.5266666666666666\n",
      "New set of weights found, iteration: 30 loss: 1.0724432 acc: 0.3466666666666667\n",
      "New set of weights found, iteration: 31 loss: 1.0636086 acc: 0.5333333333333333\n",
      "New set of weights found, iteration: 32 loss: 1.0599552 acc: 0.6366666666666667\n",
      "New set of weights found, iteration: 35 loss: 1.0583049 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 36 loss: 1.0570958 acc: 0.3466666666666667\n",
      "New set of weights found, iteration: 39 loss: 1.0469419 acc: 0.48333333333333334\n",
      "New set of weights found, iteration: 42 loss: 1.0451386 acc: 0.6333333333333333\n",
      "New set of weights found, iteration: 43 loss: 1.0374923 acc: 0.6033333333333334\n",
      "New set of weights found, iteration: 48 loss: 1.0303522 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 49 loss: 1.0292586 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 60 loss: 1.021054 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 62 loss: 1.0210088 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 63 loss: 1.0170832 acc: 0.6633333333333333\n",
      "New set of weights found, iteration: 64 loss: 1.0135772 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 65 loss: 1.0120343 acc: 0.66\n",
      "New set of weights found, iteration: 68 loss: 1.0069221 acc: 0.6433333333333333\n",
      "New set of weights found, iteration: 70 loss: 0.99110943 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 74 loss: 0.97599334 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 75 loss: 0.9725516 acc: 0.67\n",
      "New set of weights found, iteration: 77 loss: 0.9714911 acc: 0.7133333333333334\n",
      "New set of weights found, iteration: 87 loss: 0.95410764 acc: 0.7966666666666666\n",
      "New set of weights found, iteration: 89 loss: 0.9436863 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 93 loss: 0.9362148 acc: 0.65\n",
      "New set of weights found, iteration: 95 loss: 0.92910564 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 97 loss: 0.9277446 acc: 0.7333333333333333\n",
      "New set of weights found, iteration: 102 loss: 0.91819257 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 105 loss: 0.9153189 acc: 0.6466666666666666\n",
      "New set of weights found, iteration: 107 loss: 0.9071464 acc: 0.6466666666666666\n",
      "New set of weights found, iteration: 114 loss: 0.8988214 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 116 loss: 0.89690137 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 117 loss: 0.89097536 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 121 loss: 0.87916565 acc: 0.6633333333333333\n",
      "New set of weights found, iteration: 125 loss: 0.8771758 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 130 loss: 0.86686075 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 135 loss: 0.8438273 acc: 0.79\n",
      "New set of weights found, iteration: 137 loss: 0.83247876 acc: 0.6733333333333333\n",
      "New set of weights found, iteration: 138 loss: 0.82467103 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 140 loss: 0.8202214 acc: 0.6866666666666666\n",
      "New set of weights found, iteration: 141 loss: 0.806276 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 142 loss: 0.7867625 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 143 loss: 0.7699835 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 148 loss: 0.75951034 acc: 0.6966666666666667\n",
      "New set of weights found, iteration: 149 loss: 0.745888 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 151 loss: 0.74426425 acc: 0.6666666666666666\n",
      "New set of weights found, iteration: 152 loss: 0.73390484 acc: 0.8433333333333334\n",
      "New set of weights found, iteration: 156 loss: 0.7235515 acc: 0.87\n",
      "New set of weights found, iteration: 160 loss: 0.7049076 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 162 loss: 0.70258695 acc: 0.8666666666666667\n",
      "New set of weights found, iteration: 164 loss: 0.6955316 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 172 loss: 0.68481696 acc: 0.8466666666666667\n",
      "New set of weights found, iteration: 173 loss: 0.6784652 acc: 0.8366666666666667\n",
      "New set of weights found, iteration: 174 loss: 0.6691458 acc: 0.8166666666666667\n",
      "New set of weights found, iteration: 175 loss: 0.6636736 acc: 0.8166666666666667\n",
      "New set of weights found, iteration: 176 loss: 0.6603196 acc: 0.8366666666666667\n",
      "New set of weights found, iteration: 178 loss: 0.6574357 acc: 0.8533333333333334\n",
      "New set of weights found, iteration: 179 loss: 0.64556926 acc: 0.79\n",
      "New set of weights found, iteration: 183 loss: 0.63866717 acc: 0.7633333333333333\n",
      "New set of weights found, iteration: 186 loss: 0.62016314 acc: 0.7866666666666666\n",
      "New set of weights found, iteration: 190 loss: 0.60920006 acc: 0.6966666666666667\n",
      "New set of weights found, iteration: 191 loss: 0.6007828 acc: 0.7466666666666667\n",
      "New set of weights found, iteration: 192 loss: 0.5926363 acc: 0.8233333333333334\n",
      "New set of weights found, iteration: 194 loss: 0.5758982 acc: 0.8766666666666667\n",
      "New set of weights found, iteration: 195 loss: 0.5737089 acc: 0.86\n",
      "New set of weights found, iteration: 197 loss: 0.5632779 acc: 0.8566666666666667\n",
      "New set of weights found, iteration: 198 loss: 0.54802585 acc: 0.87\n",
      "New set of weights found, iteration: 200 loss: 0.54466957 acc: 0.8933333333333333\n",
      "New set of weights found, iteration: 202 loss: 0.5346576 acc: 0.8833333333333333\n",
      "New set of weights found, iteration: 204 loss: 0.5341147 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 206 loss: 0.53295857 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 209 loss: 0.5242141 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 211 loss: 0.5214254 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 212 loss: 0.52116674 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 213 loss: 0.5104606 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 215 loss: 0.50765043 acc: 0.91\n",
      "New set of weights found, iteration: 217 loss: 0.50628793 acc: 0.89\n",
      "New set of weights found, iteration: 225 loss: 0.49712422 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 226 loss: 0.49229544 acc: 0.8933333333333333\n",
      "New set of weights found, iteration: 228 loss: 0.49038848 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 229 loss: 0.48964763 acc: 0.91\n",
      "New set of weights found, iteration: 231 loss: 0.47616988 acc: 0.8966666666666666\n",
      "New set of weights found, iteration: 232 loss: 0.4750356 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 235 loss: 0.47463572 acc: 0.9\n",
      "New set of weights found, iteration: 239 loss: 0.47196954 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 243 loss: 0.46522033 acc: 0.9\n",
      "New set of weights found, iteration: 250 loss: 0.4561661 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 256 loss: 0.45460042 acc: 0.8833333333333333\n",
      "New set of weights found, iteration: 262 loss: 0.4544474 acc: 0.8866666666666667\n",
      "New set of weights found, iteration: 265 loss: 0.44849455 acc: 0.9033333333333333\n",
      "New set of weights found, iteration: 266 loss: 0.44609842 acc: 0.91\n",
      "New set of weights found, iteration: 269 loss: 0.44239476 acc: 0.91\n",
      "New set of weights found, iteration: 272 loss: 0.4422342 acc: 0.9066666666666666\n",
      "New set of weights found, iteration: 273 loss: 0.43862367 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 274 loss: 0.4360377 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 277 loss: 0.41320065 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 280 loss: 0.40165314 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 286 loss: 0.40059513 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 287 loss: 0.39764303 acc: 0.93\n",
      "New set of weights found, iteration: 288 loss: 0.3949824 acc: 0.93\n",
      "New set of weights found, iteration: 294 loss: 0.39064783 acc: 0.92\n",
      "New set of weights found, iteration: 296 loss: 0.38514143 acc: 0.92\n",
      "New set of weights found, iteration: 297 loss: 0.381598 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 302 loss: 0.38139647 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 303 loss: 0.37614173 acc: 0.92\n",
      "New set of weights found, iteration: 309 loss: 0.36768183 acc: 0.91\n",
      "New set of weights found, iteration: 313 loss: 0.3609076 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 316 loss: 0.36045584 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 321 loss: 0.35834777 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 322 loss: 0.3547752 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 327 loss: 0.35104883 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 330 loss: 0.34650895 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 332 loss: 0.3382834 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 334 loss: 0.33724326 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 338 loss: 0.32472056 acc: 0.93\n",
      "New set of weights found, iteration: 343 loss: 0.32345867 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 345 loss: 0.3217446 acc: 0.93\n",
      "New set of weights found, iteration: 347 loss: 0.32061502 acc: 0.92\n",
      "New set of weights found, iteration: 348 loss: 0.31615657 acc: 0.93\n",
      "New set of weights found, iteration: 351 loss: 0.3084577 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 354 loss: 0.30489174 acc: 0.92\n",
      "New set of weights found, iteration: 355 loss: 0.29995218 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 363 loss: 0.29957393 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 366 loss: 0.29841217 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 372 loss: 0.28985375 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 378 loss: 0.28417572 acc: 0.93\n",
      "New set of weights found, iteration: 382 loss: 0.28351793 acc: 0.93\n",
      "New set of weights found, iteration: 389 loss: 0.27943885 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 392 loss: 0.27722925 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 405 loss: 0.27528533 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 406 loss: 0.27460143 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 408 loss: 0.2710612 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 411 loss: 0.2694756 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 412 loss: 0.2649215 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 413 loss: 0.26160672 acc: 0.92\n",
      "New set of weights found, iteration: 414 loss: 0.26027718 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 418 loss: 0.25994137 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 422 loss: 0.25397167 acc: 0.92\n",
      "New set of weights found, iteration: 423 loss: 0.2534732 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 424 loss: 0.24422452 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 425 loss: 0.24326663 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 439 loss: 0.24125023 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 445 loss: 0.23965162 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 449 loss: 0.234785 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 456 loss: 0.23242655 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 457 loss: 0.23226367 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 474 loss: 0.23186895 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 475 loss: 0.23104395 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 477 loss: 0.22904079 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 478 loss: 0.2289004 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 489 loss: 0.22750992 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 502 loss: 0.22545515 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 507 loss: 0.22383133 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 514 loss: 0.2208256 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 520 loss: 0.22062747 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 521 loss: 0.2165533 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 524 loss: 0.21591477 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 525 loss: 0.21488297 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 538 loss: 0.21203747 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 544 loss: 0.20863405 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 552 loss: 0.20513496 acc: 0.91\n",
      "New set of weights found, iteration: 555 loss: 0.2047587 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 558 loss: 0.20348953 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 563 loss: 0.20212303 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 570 loss: 0.2020175 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 575 loss: 0.20133626 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 576 loss: 0.19818096 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 577 loss: 0.1979749 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 610 loss: 0.19575574 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 626 loss: 0.19487213 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 628 loss: 0.19254842 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 631 loss: 0.19105764 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 644 loss: 0.19082291 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 647 loss: 0.19066371 acc: 0.9133333333333333\n",
      "New set of weights found, iteration: 649 loss: 0.19047658 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 653 loss: 0.18974443 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 690 loss: 0.18965825 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 691 loss: 0.18952243 acc: 0.93\n",
      "New set of weights found, iteration: 696 loss: 0.18931495 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 716 loss: 0.18833008 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 719 loss: 0.18805136 acc: 0.93\n",
      "New set of weights found, iteration: 722 loss: 0.18729888 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 748 loss: 0.18719813 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 753 loss: 0.18649133 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 779 loss: 0.18517219 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 812 loss: 0.1845271 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 817 loss: 0.18398914 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 819 loss: 0.18363124 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 830 loss: 0.18298864 acc: 0.9166666666666666\n",
      "New set of weights found, iteration: 841 loss: 0.18236092 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 846 loss: 0.18167426 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 847 loss: 0.1813782 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 856 loss: 0.18133405 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 864 loss: 0.18020004 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 870 loss: 0.1799821 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 878 loss: 0.17942198 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 886 loss: 0.17817551 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 907 loss: 0.17794047 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 915 loss: 0.17786074 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 922 loss: 0.17780478 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 925 loss: 0.17758258 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 969 loss: 0.17719764 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 991 loss: 0.17705636 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1002 loss: 0.177028 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1005 loss: 0.17693754 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1007 loss: 0.17624566 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1013 loss: 0.17598782 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1020 loss: 0.17577194 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1081 loss: 0.17557582 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1082 loss: 0.17552829 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1088 loss: 0.17540139 acc: 0.93\n",
      "New set of weights found, iteration: 1089 loss: 0.17468038 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1157 loss: 0.17457508 acc: 0.93\n",
      "New set of weights found, iteration: 1162 loss: 0.17454481 acc: 0.93\n",
      "New set of weights found, iteration: 1173 loss: 0.17433043 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1177 loss: 0.17432213 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1279 loss: 0.17415431 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1370 loss: 0.17404856 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1371 loss: 0.17389564 acc: 0.9233333333333333\n",
      "New set of weights found, iteration: 1406 loss: 0.17383522 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1447 loss: 0.17379661 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1601 loss: 0.17365216 acc: 0.9266666666666666\n",
      "New set of weights found, iteration: 1653 loss: 0.17341845 acc: 0.93\n",
      "New set of weights found, iteration: 1682 loss: 0.1731208 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 1819 loss: 0.17306708 acc: 0.9366666666666666\n",
      "New set of weights found, iteration: 1821 loss: 0.17294748 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 2221 loss: 0.17294282 acc: 0.93\n",
      "New set of weights found, iteration: 2575 loss: 0.17288338 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 3079 loss: 0.17281877 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 5383 loss: 0.17281146 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 5973 loss: 0.17280106 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 7446 loss: 0.17280102 acc: 0.9333333333333333\n",
      "New set of weights found, iteration: 9397 loss: 0.17279711 acc: 0.93\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10000):\n",
    "\n",
    "    # Update weights with some small random values\n",
    "    dense1.weights += 0.05 * np.random.randn(2, 3)\n",
    "    dense1.biases += 0.05 * np.random.randn(1, 3)\n",
    "    dense2.weights += 0.05 * np.random.randn(3, 3)\n",
    "    dense2.biases += 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # it takes the output of second dense layer here and returns loss\n",
    "    loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # calculate values along first axis\n",
    "    predictions = np.argmax(activation2.output, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    # If loss is smaller - print and save weights and biases aside\n",
    "    if loss < lowest_loss:\n",
    "        print('New set of weights found, iteration:', iteration,\n",
    "              'loss:', loss, 'acc:', accuracy)\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense2.weights.copy()\n",
    "        best_dense2_biases = dense2.biases.copy()\n",
    "        lowest_loss = loss\n",
    "    # Revert weights and biases\n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b235c-2410-461d-8673-a0d4e24ec281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
